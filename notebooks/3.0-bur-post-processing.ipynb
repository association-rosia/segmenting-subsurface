{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "label_path = f'../data/every-layer-submission-sample/sub_vol_50.npy'\n",
    "vol = np.load(label_path, allow_pickle=True)\n",
    "volume = vol\n",
    "print(vol.shape)\n",
    "coordinates_tuples = []\n",
    "for i in range(volume.shape[0]):\n",
    "    for j in range(volume.shape[1]):\n",
    "        for k in range(volume.shape[2]):\n",
    "            if i == 0 or i == volume.shape[0] - 1 or j == 0 or j == volume.shape[1] - 1 or k == 0 or k == volume.shape[2] - 1:\n",
    "                x_coord = i\n",
    "                y_coord = j\n",
    "                z_coord = k\n",
    "                coordinates_tuples.append([x_coord, y_coord, z_coord, volume[i, j, k]])\n",
    "\n",
    "arr = np.asarray(coordinates_tuples)\n",
    "# frames.append(go.Frame(\n",
    "data=go.Scatter3d(\n",
    "    x=arr[:, 0], y=arr[:, 1], z=arr[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=1,\n",
    "        # color=np.full(arr.shape[0], k),                # set color to an array/list of desired values\n",
    "        color=arr[:, 3],\n",
    "        colorscale='Viridis',   # choose a colorscale\n",
    "        opacity=1,\n",
    "    ),\n",
    ")#,\n",
    "    # name=str(k) # you need to name the frame for the animation to behave properly\n",
    "    # ))\n",
    "                \n",
    "fig = go.Figure(data=data)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# from skimage import io\n",
    "\n",
    "label_path = f'../data/every-layer-submission-sample/sub_vol_50.npy'\n",
    "vol = np.load(label_path, allow_pickle=True)\n",
    "volume = vol.T\n",
    "# volume = volume[:100, :100, :100]\n",
    "r, c = volume[0].shape\n",
    "print(vol.shape, volume.shape)\n",
    "# Define frames\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "nb_frames = len(np.unique(volume))\n",
    "\n",
    "coordinates_tuples = []\n",
    "for x in range(volume.shape[0]):\n",
    "    for y in range(volume.shape[1]):\n",
    "        for z in range(volume.shape[2]):\n",
    "            x_coord = x\n",
    "            y_coord = y\n",
    "            z_coord = z\n",
    "            coordinates_tuples.append([x_coord, y_coord, z_coord, volume[x, y, z]])\n",
    "\n",
    "arr = np.asarray(coordinates_tuples)\n",
    "\n",
    "frames = []\n",
    "for c in range(nb_frames):\n",
    "    sub_arr = arr[arr[:, 3] == c]\n",
    "    frames.append(go.Frame(\n",
    "        data=go.Scatter3d(\n",
    "            x=sub_arr[:, 0], y=sub_arr[:, 1], z=sub_arr[:, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                color=np.full(sub_arr.shape[0], c),                # set color to an array/list of desired values\n",
    "                colorscale='Viridis',   # choose a colorscale\n",
    "                opacity=0.8,\n",
    "                cmin=0,\n",
    "                cmax=nb_frames\n",
    "            )\n",
    "        ),\n",
    "        name=str(c) # you need to name the frame for the animation to behave properly\n",
    "        ))\n",
    "                \n",
    "fig = go.Figure(frames=frames)\n",
    "\n",
    "# Add data to be displayed before animation starts\n",
    "# fig.add_trace(go.Surface(\n",
    "#     z=volume[0]\n",
    "#     ))\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=sub_arr[:, 0], y=sub_arr[:, 1], z=sub_arr[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        color=np.full(sub_arr.shape[0], c),                # set color to an array/list of desired values\n",
    "        colorscale='Viridis',   # choose a colorscale\n",
    "        opacity=0.8,\n",
    "        cmin=0,\n",
    "        cmax=nb_frames\n",
    "    ),\n",
    "))\n",
    "\n",
    "def frame_args(duration):\n",
    "    return {\n",
    "            \"frame\": {\"duration\": duration},\n",
    "            \"mode\": \"immediate\",\n",
    "            \"fromcurrent\": True,\n",
    "            \"transition\": {\"duration\": duration, \"easing\": \"linear\"},\n",
    "        }\n",
    "\n",
    "sliders = [\n",
    "            {\n",
    "                \"pad\": {\"b\": 10, \"t\": 60},\n",
    "                \"len\": 0.9,\n",
    "                \"x\": 0.1,\n",
    "                \"y\": 0,\n",
    "                \"steps\": [\n",
    "                    {\n",
    "                        \"args\": [[f.name], frame_args(0)],\n",
    "                        \"label\": str(k),\n",
    "                        \"method\": \"animate\",\n",
    "                    }\n",
    "                    for k, f in enumerate(fig.frames)\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "\n",
    "# Layout\n",
    "fig.update_layout(\n",
    "         title='Slices in volumetric data',\n",
    "         width=600,\n",
    "         height=600,\n",
    "         scene = dict(\n",
    "            xaxis = dict(range=[0,100]),\n",
    "            yaxis = dict(range=[0,100]),\n",
    "            zaxis = dict(range=[0,100]),\n",
    "            aspectratio=dict(x=1, y=1, z=1),),\n",
    "         updatemenus = [\n",
    "            {\n",
    "                \"buttons\": [\n",
    "                    {\n",
    "                        \"args\": [None, frame_args(100)],\n",
    "                        \"label\": \"&#9654;\", # play symbol\n",
    "                        \"method\": \"animate\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"args\": [[None], frame_args(0)],\n",
    "                        \"label\": \"&#9724;\", # pause symbol\n",
    "                        \"method\": \"animate\",\n",
    "                    },\n",
    "                ],\n",
    "                \"direction\": \"left\",\n",
    "                \"pad\": {\"r\": 10, \"t\": 70},\n",
    "                \"type\": \"buttons\",\n",
    "                \"x\": 0.1,\n",
    "                \"y\": 0,\n",
    "            }\n",
    "         ],\n",
    "         sliders=sliders\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional.classification import dice\n",
    "import torch\n",
    "\n",
    "\n",
    "preds = torch.tensor([[[0.9, 0.5, .8, .9]]])\n",
    "target = torch.tensor([[[1, 1, 0, 0]]])\n",
    "print(dice(preds, target, num_classes=2, threshold=0.8, multiclass=True))\n",
    "\n",
    "preds = torch.tensor([[[0.9, 0.5, .8, .9]]])\n",
    "target = torch.tensor([[[0, 0, 1, 0]]])\n",
    "print(dice(preds, target, num_classes=2, threshold=0.8, multiclass=True))\n",
    "\n",
    "preds = torch.tensor([[[0.5, 0.5, .5, .9]]])\n",
    "target = torch.tensor([[[0, 0, 0, 1]]])\n",
    "print(dice(preds, target, num_classes=2, threshold=0.8, multiclass=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional.classification import dice\n",
    "import torch\n",
    "\n",
    "\n",
    "preds = torch.tensor([[[0.9, 0.5, .8, .9], [0.9, 0.5, .8, .9]], [[0.5, 0.5, .5, .9], [0.5, 0.5, .5, .9]]])\n",
    "target = torch.tensor([[[1, 1, 0, 0], [0, 0, 1, 0]], [[0, 0, 0, 1], [0, 0, 0, 1]]])\n",
    "dice(preds, target, num_classes=2, threshold=0.8, average='macro', multiclass=True, mdmc_average='samplewise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((0.25 + 0.5) / 2 + (1  + 1) / 2 ) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = f'../data/every-layer-submission-sample/sub_vol_50.npy'\n",
    "vol = np.load(label_path, allow_pickle=True)\n",
    "volume = vol\n",
    "print(vol.shape)\n",
    "_max = np.max(volume)\n",
    "coordinates_tuples = []\n",
    "for i in range(volume.shape[0]):\n",
    "    for j in range(volume.shape[1]):\n",
    "        for k in range(volume.shape[2]):\n",
    "            if i == 0 or i == volume.shape[0] - 1 or j == 0 or j == volume.shape[1] - 1 or k == 0 or k == volume.shape[2] - 1:\n",
    "                x_coord = i\n",
    "                y_coord = j\n",
    "                z_coord = k\n",
    "                if i % 2 == 0:\n",
    "                    value = _max - volume[i, j, k]\n",
    "                else:\n",
    "                    value = volume[i, j, k]\n",
    "                coordinates_tuples.append([x_coord, y_coord, z_coord, value])\n",
    "\n",
    "arr = np.asarray(coordinates_tuples)\n",
    "# frames.append(go.Frame(\n",
    "data=go.Scatter3d(\n",
    "    x=arr[:, 0], y=arr[:, 1], z=arr[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=1,\n",
    "        # color=np.full(arr.shape[0], k),                # set color to an array/list of desired values\n",
    "        color=arr[:, 3],\n",
    "        colorscale='Viridis',   # choose a colorscale\n",
    "        opacity=1,\n",
    "    ),\n",
    ")#,\n",
    "    # name=str(k) # you need to name the frame for the animation to behave properly\n",
    "    # ))\n",
    "                \n",
    "fig = go.Figure(data=data)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = f'../data/every-layer-submission-sample/sub_vol_50.npy'\n",
    "vol = np.load(label_path, allow_pickle=True)\n",
    "volume = vol\n",
    "print(vol.shape)\n",
    "_max = np.max(volume)\n",
    "coordinates_tuples = []\n",
    "for i in range(volume.shape[0]):\n",
    "    for j in range(volume.shape[1]):\n",
    "        for k in range(volume.shape[2]):\n",
    "            if i == 0 or i == volume.shape[0] - 1 or j == 0 or j == volume.shape[1] - 1 or k == 0 or k == volume.shape[2] - 1:\n",
    "                x_coord = i\n",
    "                y_coord = j\n",
    "                z_coord = k\n",
    "                if j % 2 == 0:\n",
    "                    value = _max - volume[i, j, k]\n",
    "                else:\n",
    "                    value = volume[i, j, k]\n",
    "                coordinates_tuples.append([x_coord, y_coord, z_coord, value])\n",
    "\n",
    "arr = np.asarray(coordinates_tuples)\n",
    "# frames.append(go.Frame(\n",
    "data=go.Scatter3d(\n",
    "    x=arr[:, 0], y=arr[:, 1], z=arr[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=1,\n",
    "        # color=np.full(arr.shape[0], k),                # set color to an array/list of desired values\n",
    "        color=arr[:, 3],\n",
    "        colorscale='Viridis',   # choose a colorscale\n",
    "        opacity=1,\n",
    "    ),\n",
    ")#,\n",
    "    # name=str(k) # you need to name the frame for the animation to behave properly\n",
    "    # ))\n",
    "                \n",
    "fig = go.Figure(data=data)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = f'../data/every-layer-submission-sample/sub_vol_50.npy'\n",
    "vol = np.load(label_path, allow_pickle=True)\n",
    "volume = vol\n",
    "print(vol.shape)\n",
    "_max = np.max(volume)\n",
    "coordinates_tuples = []\n",
    "for i in range(volume.shape[0]):\n",
    "    for j in range(volume.shape[1]):\n",
    "        for k in range(volume.shape[2]):\n",
    "            if i == 0 or i == volume.shape[0] - 1 or j == 0 or j == volume.shape[1] - 1 or k == 0 or k == volume.shape[2] - 1:\n",
    "                x_coord = i\n",
    "                y_coord = j\n",
    "                z_coord = k\n",
    "                if k % 2 == 0:\n",
    "                    value = _max - volume[i, j, k]\n",
    "                else:\n",
    "                    value = volume[i, j, k]\n",
    "                coordinates_tuples.append([x_coord, y_coord, z_coord, value])\n",
    "\n",
    "arr = np.asarray(coordinates_tuples)\n",
    "# frames.append(go.Frame(\n",
    "data=go.Scatter3d(\n",
    "    x=arr[:, 0], y=arr[:, 1], z=arr[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=1,\n",
    "        # color=np.full(arr.shape[0], k),                # set color to an array/list of desired values\n",
    "        color=arr[:, 3],\n",
    "        colorscale='Viridis',   # choose a colorscale\n",
    "        opacity=1,\n",
    "    ),\n",
    ")#,\n",
    "    # name=str(k) # you need to name the frame for the animation to behave properly\n",
    "    # ))\n",
    "                \n",
    "fig = go.Figure(data=data)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation des masks id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def init_instance_volume_optimise(volume, dim):\n",
    "    # Utiliser np.moveaxis pour traiter les dimensions de manière plus générique\n",
    "    volume = np.moveaxis(volume, dim, 0)\n",
    "\n",
    "    # Appliquer la logique de la fonction de manière vectorisée\n",
    "    unique_values = np.unique(volume[1])\n",
    "    id_instances = np.arange(len(unique_values))\n",
    "    \n",
    "    mask = volume[1] != 0\n",
    "    instance_mapping = np.zeros_like(volume[1])\n",
    "    \n",
    "    for new_id, old_id in zip(id_instances, unique_values):\n",
    "        instance_mapping = np.where(volume[1] == old_id, new_id, instance_mapping)\n",
    "\n",
    "    volume[1] = np.where(mask, instance_mapping, 0)\n",
    "\n",
    "    # Rétablir l'ordre des dimensions original\n",
    "    volume = np.moveaxis(volume, 0, dim)\n",
    "\n",
    "    return volume\n",
    "\n",
    "def init_instance_volume(volume, dim) -> np.ndarray:\n",
    "    id_instance = 0\n",
    "    volume = np.moveaxis(volume, dim, 0)\n",
    "    \n",
    "    for i in range(volume.shape[0]):\n",
    "        instance_slice = volume[i, :, :, 1]\n",
    "        \n",
    "        for id in np.unique(instance_slice):\n",
    "            instance_slice = np.where(instance_slice == id, id_instance, instance_slice)\n",
    "            id_instance += 1\n",
    "        \n",
    "        volume[i, :, :, 1] = instance_slice\n",
    "    \n",
    "    volume = np.moveaxis(volume, 0, dim)\n",
    "    \n",
    "    return volume\n",
    "\n",
    "# Exemple d'utilisation\n",
    "volume = np.random.randint(0, 5, (3, 4, 4, 2))\n",
    "\n",
    "dim = 1  # ou 0 pour tester l'autre dimension\n",
    "resultat_opt = init_instance_volume_optimise(volume.copy(), dim)\n",
    "resultat = init_instance_volume(volume.copy(), dim)\n",
    "print((resultat == resultat_opt).all())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 2]\n",
      " [1 2 0 3]\n",
      " [2 4 2 3]]\n",
      "[[10 11 11 12]\n",
      " [11 12 10 13]\n",
      " [12 14 12 13]]\n"
     ]
    }
   ],
   "source": [
    "print(resultat_opt[:, 2, :, 1])\n",
    "print(resultat[:, 2, :, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul du taux de recouvrement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation\n",
    "tableau1 = np.array([1, 2, 1, 3, 2, 3, 4, 4, 1]*1000000)\n",
    "tableau2 = np.array([10, 20, 10, 30, 20, 30, 40, 40, 40]*1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{10: array([nan,  1.,  0.,  0.,  0., nan]), 20: array([nan,  0.,  1.,  0.,  0., nan]), 30: array([nan,  0.,  0.,  1.,  0., nan]), 40: array([       nan, 0.33333333, 0.        , 0.        , 0.66666667,\n",
      "              nan])}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_id_mapper(sub_slice, sub_ref_slice, nb_mask):\n",
    "    # Retrouver les masque disponible sur la slice\n",
    "    mask_slice = np.unique(sub_slice).astype(np.int16)\n",
    "    \n",
    "    # Fusionner les deux tableaux en une seule matrice 2D\n",
    "    tableau_combine = np.column_stack((sub_ref_slice, sub_slice))\n",
    "\n",
    "    # Utiliser numpy.unique pour obtenir les valeurs uniques et leurs occurrences\n",
    "    tuples_uniques, tuples_occurrences = np.unique(tableau_combine, axis=0, return_counts=True)\n",
    "    valeurs_uniques, occurrences = np.unique(sub_ref_slice, return_counts=True)\n",
    "\n",
    "    # Créer le tableau 2D avec les tuples uniques et les taux de répartition\n",
    "    tuples_occurrences = tuples_occurrences.astype(np.float64)\n",
    "\n",
    "    # Utiliser np.searchsorted pour obtenir les indices des valeurs uniques dans valeurs_uniques\n",
    "    indices_occurrences = np.searchsorted(valeurs_uniques, tuples_uniques[:, 0])\n",
    "    # Mettre à jour le taux de répartition avec les valeurs correspondantes\n",
    "    tuples_occurrences /= occurrences[indices_occurrences]\n",
    "\n",
    "    # Créer le dictionnaire final\n",
    "    id_mapper = {}\n",
    "    for val in valeurs_uniques:\n",
    "        rates = np.full(nb_mask, np.nan)\n",
    "        rates[mask_slice] = 0\n",
    "        indices_val = np.where(tuples_uniques[:, 0] == val)\n",
    "        rates[tuples_uniques[indices_val, 1]] = tuples_occurrences[indices_val]\n",
    "        id_mapper[val] = rates\n",
    "\n",
    "    return id_mapper\n",
    "\n",
    "# Exemple d'utilisation\n",
    "sub_slice = np.array([1, 2, 1, 3, 2, 3, 4, 4, 1])\n",
    "sub_ref_slice = np.array([10, 20, 10, 30, 20, 30, 40, 40, 40])\n",
    "nb_mask = 6\n",
    "\n",
    "resultat = create_id_mapper(sub_slice, sub_ref_slice, nb_mask)\n",
    "print(resultat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.add(np.array([np.nan,  1.,  0.,  0.,  0., np.nan]), np.array([1,  1.,  0.,  0.,  0., np.nan]))\n",
    "np.nan + 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unification des groupes de mask à travers les slices de référence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib.nanfunctions import _copyto, _replace_nan\n",
    "\n",
    "def numpy_nansum(a, axis=None):\n",
    "    a, mask = _replace_nan(a, 0)\n",
    "\n",
    "    if mask is None:\n",
    "        return np.sum(a, axis=axis, keepdims=False)\n",
    "    mask = np.all(mask, axis=axis)\n",
    "    tot = np.sum(a, axis=axis, keepdims=False)\n",
    "    if np.any(mask):\n",
    "        tot = _copyto(tot, np.nan, mask)\n",
    "    return tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan,  1., nan,  1., nan],\n",
       "       [ 1., nan,  1., nan,  1., nan, nan,  1., nan, nan,  1., nan, nan,\n",
       "         1., nan, nan,  1., nan, nan,  1., nan, nan,  1., nan,  1.],\n",
       "       [nan,  1., nan,  1., nan,  1., nan, nan,  1., nan, nan,  1., nan,\n",
       "        nan,  1., nan, nan,  1., nan, nan,  1., nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan,  1., nan, nan,  1., nan,  1., nan],\n",
       "       [ 1., nan,  1., nan,  1., nan, nan,  1., nan, nan,  1., nan, nan,\n",
       "         1., nan, nan,  1., nan, nan,  1., nan, nan,  1., nan,  1.],\n",
       "       [nan,  1., nan,  1., nan,  1., nan, nan,  1., nan, nan,  1., nan,\n",
       "        nan,  1., nan, nan,  1., nan, nan,  1., nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan,  1., nan, nan,  1., nan,  1., nan],\n",
       "       [ 1., nan,  1., nan,  1., nan, nan,  1., nan, nan,  1., nan, nan,\n",
       "         1., nan, nan,  1., nan, nan,  1., nan, nan,  1., nan,  1.],\n",
       "       [nan,  1., nan,  1., nan,  1., nan, nan,  1., nan, nan,  1., nan,\n",
       "        nan,  1., nan, nan,  1., nan, nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan,  1., nan, nan,  1., nan, nan,  1., nan,  1., nan],\n",
       "       [ 1., nan,  1., nan,  1., nan, nan,  1., nan, nan,  1., nan, nan,\n",
       "         1., nan, nan,  1., nan, nan,  1., nan, nan,  1., nan,  1.],\n",
       "       [nan,  1., nan,  1., nan,  1., nan, nan,  1., nan, nan,  1., nan,\n",
       "        nan,  1., nan, nan,  1., nan, nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan,  1., nan, nan,  1., nan, nan,  1., nan,  1., nan],\n",
       "       [ 1., nan,  1., nan,  1., nan, nan,  1., nan, nan,  1., nan, nan,\n",
       "         1., nan, nan,  1., nan, nan,  1., nan, nan,  1., nan,  1.],\n",
       "       [nan,  1., nan,  1., nan,  1., nan, nan,  1., nan, nan,  1., nan,\n",
       "        nan,  1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,  1.,\n",
       "        nan, nan,  1., nan, nan,  1., nan, nan,  1., nan,  1., nan],\n",
       "       [ 1., nan,  1., nan,  1., nan, nan,  1., nan, nan,  1., nan, nan,\n",
       "         1., nan, nan,  1., nan, nan,  1., nan, nan,  1., nan,  1.],\n",
       "       [nan,  1., nan,  1., nan,  1., nan, nan,  1., nan, nan,  1., nan,\n",
       "        nan,  1., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,  1.,\n",
       "        nan, nan,  1., nan, nan,  1., nan, nan,  1., nan,  1., nan],\n",
       "       [ 1., nan,  1., nan,  1., nan, nan,  1., nan, nan,  1., nan, nan,\n",
       "         1., nan, nan,  1., nan, nan,  1., nan, nan,  1., nan,  1.],\n",
       "       [nan,  1., nan,  1., nan,  1., nan, nan,  1., nan, nan,  1., nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan,  1., nan, nan,  1.,\n",
       "        nan, nan,  1., nan, nan,  1., nan, nan,  1., nan,  1., nan],\n",
       "       [ 1., nan,  1., nan,  1., nan, nan,  1., nan, nan,  1., nan, nan,\n",
       "         1., nan, nan,  1., nan, nan,  1., nan, nan,  1., nan,  1.],\n",
       "       [nan,  1., nan,  1., nan,  1., nan, nan,  1., nan, nan,  1., nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan,  1., nan, nan,  1.,\n",
       "        nan, nan,  1., nan, nan,  1., nan, nan,  1., nan,  1., nan],\n",
       "       [ 1., nan,  1., nan,  1., nan, nan,  1., nan, nan,  1., nan, nan,\n",
       "         1., nan, nan,  1., nan, nan,  1., nan, nan,  1., nan,  1.],\n",
       "       [nan,  1., nan,  1., nan,  1., nan, nan,  1., nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan,  1., nan, nan,  1., nan, nan,  1.,\n",
       "        nan, nan,  1., nan, nan,  1., nan, nan,  1., nan,  1., nan],\n",
       "       [ 1., nan,  1., nan,  1., nan, nan,  1., nan, nan,  1., nan, nan,\n",
       "         1., nan, nan,  1., nan, nan,  1., nan, nan,  1., nan,  1.],\n",
       "       [nan,  1., nan,  1., nan,  1., nan, nan,  1., nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
       "      dtype=float16)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def load_slice(slice_dir: str, slice_num: int) -> np.ndarray:\n",
    "    slice_name = f\"{slice_num:03}\"\n",
    "    slice_path = os.path.join(slice_dir, slice_name)\n",
    "    \n",
    "    return np.load(slice_path)\n",
    "\n",
    "# def load_volume(volume_dir, dim: int) -> np.ndarray:\n",
    "#     slice_dir = os.path.join(volume_dir, str(dim))\n",
    "#     list_slice = []\n",
    "#     for slice_num in range(300):\n",
    "#         list_slice.append(\n",
    "#             load_slice(slice_dir, slice_num)\n",
    "#         )\n",
    "    \n",
    "#     return np.stack(list_slice)\n",
    "def load_volume(volume_dir, dim: int) -> np.ndarray:\n",
    "    label_path = f'../data/every-layer-submission-sample/sub_vol_50.npy'\n",
    "    volume = np.load(label_path, allow_pickle=True)\n",
    "    # volume = volume[:100, :100, :100]\n",
    "    volume = volume[:10, :10, :10]\n",
    "    # volume = volume[:5, :5, :5]\n",
    "\n",
    "    binary_prob = np.random.rand(*volume.shape)\n",
    "    volume = np.stack([binary_prob, volume], axis=-1)\n",
    "    \n",
    "    return volume\n",
    "\n",
    "\n",
    "def init_instance_volume(volume: np.ndarray, dim: int) -> np.ndarray:\n",
    "    id_instance = 0\n",
    "    volume = np.moveaxis(volume, dim, 0)\n",
    "    \n",
    "    for i in range(volume.shape[0]):\n",
    "        instance_slice = volume[i, :, :, 1]\n",
    "        new_instance_slice = np.zeros(instance_slice.shape, dtype=np.float16)\n",
    "        for id in np.unique(instance_slice):\n",
    "            new_instance_slice = np.where(instance_slice == id, id_instance, new_instance_slice)\n",
    "            id_instance += 1\n",
    "        \n",
    "        volume[i, :, :, 1] = new_instance_slice\n",
    "        \n",
    "    volume = np.moveaxis(volume, 0, dim)\n",
    "    \n",
    "    return volume, id_instance\n",
    "\n",
    "    \n",
    "def update_groups_masks(groups_masks, sub_slice_pred, sub_slice_ref):\n",
    "    sub_slice_pred = sub_slice_pred.astype(np.int32)\n",
    "    sub_slice_ref = sub_slice_ref.astype(np.int32)\n",
    "    # Fusionner les deux tableaux en une seule matrice 2D\n",
    "    tableau_combine = np.column_stack((sub_slice_ref, sub_slice_pred))\n",
    "    # Utiliser numpy.unique pour obtenir les valeurs uniques et leurs occurrences\n",
    "    unique_ref = np.unique(sub_slice_ref, return_counts=False)\n",
    "    unique_pred = np.unique(sub_slice_pred, return_counts=False)\n",
    "    \n",
    "    groups_masks[unique_ref, unique_pred] = 0\n",
    "    \n",
    "    tuples_uniques, tuples_occurrences = np.unique(tableau_combine, axis=0, return_counts=True)\n",
    "    groups_masks[tuples_uniques[:, 0], tuples_uniques[:, 1]] = tuples_occurrences\n",
    "    groups_masks[unique_ref] = groups_masks[unique_ref] / np.nansum(groups_masks[unique_ref], axis=0)\n",
    "        \n",
    "    return groups_masks\n",
    "\n",
    "\n",
    "def create_groups_masks(volume_pred: np.ndarray, volume_ref: np.ndarray, nb_mask_pred, nb_mask_ref) -> np.ndarray:\n",
    "    groups_masks = np.full((nb_mask_ref, nb_mask_pred), np.nan, dtype=np.float16)\n",
    "    for ref_idx in range(volume_ref.shape[1]):\n",
    "        for pred_idx in range(volume_pred.shape[0]):\n",
    "            groups_masks = update_groups_masks(groups_masks, volume_pred[pred_idx, ref_idx, :, 1], volume_ref[pred_idx, ref_idx, :, 1])\n",
    "    \n",
    "    return groups_masks\n",
    "\n",
    "# Je suppose que mon volume fait X Y Z C\n",
    "# X = 300 : axes des X\n",
    "# Y = 300 : axes des Y\n",
    "# C = 2 : probabilité binaire, instance id\n",
    "def merge_volumes(run_name, volume_name):\n",
    "    volume_dir = os.path.join(\n",
    "        # get_config['submissions']['root'],\n",
    "        run_name,\n",
    "        volume_name\n",
    "    )\n",
    "    \n",
    "    volume_0 = load_volume(volume_dir, dim=0)\n",
    "    # Create a unique id for each masks of the volume\n",
    "    volume_0, nb_mask_0 = init_instance_volume(volume_0, dim=0)\n",
    "    \n",
    "    volume_1 = load_volume(volume_dir, dim=1)\n",
    "    # Create a unique id for each masks of the volume\n",
    "    volume_1, nb_mask_1 = init_instance_volume(volume_1, dim=1)\n",
    "    \n",
    "    # Création de groupes de masque pour chaque slide de référence\n",
    "    groups_masks = create_groups_masks(volume_0, volume_1, nb_mask_0, nb_mask_1)\n",
    "    # Algorithme permettant de passer de goupes de masque par slice à un set de groupe de masque \n",
    "    # répertoriant de manière unique chaque id d'instance\n",
    "    # masks_groups_unified = unifie_mask_groups(list_mask_groups)\n",
    "    return groups_masks\n",
    "\n",
    "list_mask_groups = merge_volumes('', '')\n",
    "list_mask_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([False,  True]), array([  752086, 36473570]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(np.isnan(list_mask_groups), return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 25)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_mask_groups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
       "        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.],\n",
       "       [1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "        0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.],\n",
       "       [1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
       "        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.],\n",
       "       [0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
       "        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.],\n",
       "       [1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "        0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.],\n",
       "       [1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
       "        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.],\n",
       "       [0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
       "        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.],\n",
       "       [1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "        0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.],\n",
       "       [1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
       "        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.],\n",
       "       [0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
       "        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.],\n",
       "       [1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "        0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.],\n",
       "       [1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
       "        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.],\n",
       "       [0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
       "        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.],\n",
       "       [1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "        0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.],\n",
       "       [1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
       "        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.],\n",
       "       [0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
       "        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.],\n",
       "       [1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "        0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.],\n",
       "       [1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
       "        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.],\n",
       "       [0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
       "        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.],\n",
       "       [1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "        0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.],\n",
       "       [1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
       "        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.],\n",
       "       [0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
       "        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.],\n",
       "       [1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "        0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.],\n",
       "       [1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
       "        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.],\n",
       "       [0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
       "        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.],\n",
       "       [1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "        0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.],\n",
       "       [1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
       "        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.],\n",
       "       [0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
       "        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.],\n",
       "       [1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "        0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.],\n",
       "       [1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
       "        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# all_mask_groups = np.concatenate(list_mask_groups)\n",
    "all_mask_groups = list_mask_groups\n",
    "# distance_matrix = pairwise_distances(all_mask_groups, metric='cosine', force_all_finite='allow-nan')\n",
    "def custom_cosine_distance(x: np.ndarray, y: np.ndarray):\n",
    "    xna = np.invert(np.isnan(x))\n",
    "    x = x[xna]\n",
    "    y = y[xna]\n",
    "    \n",
    "    yna = np.invert(np.isnan(y))\n",
    "    x = x[yna]\n",
    "    y = y[yna]\n",
    "    \n",
    "    # print(x)\n",
    "    \n",
    "    if len(x) == 0 or len(y) == 0 or np.all(x == 0) or np.all(y == 0):\n",
    "        return 1\n",
    "    # Compute cosine similarity\n",
    "    distance = cosine(x, y)\n",
    "    \n",
    "    return distance\n",
    "\n",
    "distance_matrix = pairwise_distances(all_mask_groups, metric=custom_cosine_distance, force_all_finite='allow-nan')\n",
    "\n",
    "# start = 0\n",
    "# for group in list_mask_groups:\n",
    "#     end = start + len(group)\n",
    "#     distance_matrix[start:end, start:end] = 1\n",
    "#     start = end\n",
    "\n",
    "distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " array([2, 1, 0, 2, 1, 0, 2, 1, 0, 2, 1, 0, 2, 1, 0, 2, 1, 0, 2, 1, 0, 2,\n",
       "        1, 0, 2, 1, 0, 2, 1, 0]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "clustering = AgglomerativeClustering(\n",
    "    n_clusters=None,\n",
    "    distance_threshold=0.5,\n",
    "    compute_full_tree=True,\n",
    "    metric='precomputed',\n",
    "    linkage='average'\n",
    ")\n",
    "labels = clustering.fit_predict(distance_matrix)\n",
    "\n",
    "len(np.unique(labels)), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
       "        13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24.]),\n",
       " array([54, 46, 60, 40, 66, 34,  1, 74, 25,  4, 78, 18,  8, 82, 10, 14, 80,\n",
       "         6, 22, 76,  2, 30, 70, 39, 61]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume = load_volume(None, None)\n",
    "volume, nb_mask = init_instance_volume(volume, 0)\n",
    "np.unique(volume[:, :, :, 1], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., 10.,  0., 10.,  0., 10.,  0.,  0., 10.,  0.,  0.,  8.,  0.,\n",
       "         0.,  6.,  0.,  0.,  4.,  0.,  0.,  2.,  0.,  0.,  0.,  0.],\n",
       "       [10.,  0., 10.,  0., 10.,  0.,  0., 10.,  0.,  0., 10.,  0.,  0.,\n",
       "        10.,  0.,  0., 10.,  0.,  0., 10.,  0.,  0., 10.,  0., 10.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  3.,  0.,  0.,  5.,\n",
       "         0.,  0.,  7.,  0.,  0.,  9.,  0.,  0., 10.,  0., 10.,  0.]],\n",
       "      dtype=float16)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_vector = np.zeros((len(np.unique(labels)), nb_mask), dtype=np.float16)\n",
    "for mask_group, label in zip(all_mask_groups, labels):\n",
    "    cluster_vector[label] = numpy_nansum(np.stack((cluster_vector[label], mask_group)), axis=0)\n",
    "    \n",
    "cluster_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 2 1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20488de24d304f5eaf2b31e44c9219ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2.]), array([181, 701, 118]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "max_indices = np.argmax(cluster_vector, axis=0)\n",
    "\n",
    "# Afficher les indices\n",
    "print(max_indices)\n",
    "\n",
    "volume_consitant = volume.copy()\n",
    "for instance, id in tqdm(list(enumerate(max_indices))):\n",
    "    volume_consitant[:, : ,: , 1] = np.where(volume[:, : ,: , 1] == instance, id, volume_consitant[:, : ,: , 1])\n",
    "unique_pred, count_pred = np.unique(volume_consitant[:, : ,: , 1], return_counts=True)\n",
    "unique_pred, count_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2., 3., 4., 5., 6., 7., 8.]),\n",
       " array([ 49689, 111350,  71221, 179743, 196010,  53968, 140183,  57444,\n",
       "        140392]))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(volume_consitant[:, : ,: , 1], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, array([4, 5, 6], dtype=int8), array([118, 701, 181]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_volume_test() -> np.ndarray:\n",
    "    label_path = f'../data/every-layer-submission-sample/sub_vol_50.npy'\n",
    "    volume = np.load(label_path, allow_pickle=True)\n",
    "    # volume = volume[:100, :100, :100]\n",
    "    volume = volume[:10, :10, :10]\n",
    "    # volume = volume[:7, :7, :7]\n",
    "    # binary_prob = np.random.rand(*volume.shape)\n",
    "    # volume = np.stack([binary_prob, volume], axis=-1)\n",
    "    \n",
    "    return volume\n",
    "\n",
    "unique, count = np.unique(load_volume_test(), return_counts=True)\n",
    "len(unique), unique, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False,  True, False, False,\n",
       "       False,  True,  True,  True,  True, False])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(count_pred) == np.sort(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vesuvius-challenge-ink-detection-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
